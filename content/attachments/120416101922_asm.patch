diff --git a/arch/mips/include/asm/checksum.h b/arch/mips/include/asm/checksum.h
index f2f7c6c..61f5d93 100644
--- a/arch/mips/include/asm/checksum.h
+++ b/arch/mips/include/asm/checksum.h
@@ -193,11 +198,20 @@ static inline __sum16 ip_compute_csum(const void *buff, int len)
 }
 
 #define _HAVE_ARCH_IPV6_CSUM
+static __inline__ __sum16 csum_ipv6_unaligned_magic(const struct in6_addr *saddr,
+				          const struct in6_addr *daddr,
+					  __u32 len, unsigned short proto,
+					  __wsum sum);
+
 static __inline__ __sum16 csum_ipv6_magic(const struct in6_addr *saddr,
 				          const struct in6_addr *daddr,
 					  __u32 len, unsigned short proto,
 					  __wsum sum)
 {
+	if ((((__u32) saddr) | ((__u32) daddr)) & 3) {
+		/* Unaligned to word boundaries... */
+		return csum_ipv6_unaligned_magic(saddr, daddr, len, proto, sum);
+	}
 	__asm__(
 	"	.set	push		# csum_ipv6_magic\n"
 	"	.set	noreorder	\n"
@@ -257,4 +271,117 @@ static __inline__ __sum16 csum_ipv6_magic(const struct in6_addr *saddr,
 	return csum_fold(sum);
 }
 
+static __inline__ __sum16 csum_ipv6_unaligned_magic(const struct in6_addr *saddr,
+				          const struct in6_addr *daddr,
+					  __u32 len, unsigned short proto,
+					  __wsum sum)
+{
+	__asm__(
+	"	.set	push		# csum_ipv6_magic\n"
+	"	.set	noreorder	\n"
+	"	.set	noat		\n"
+	"	addu	%0, %5		# proto (long in network byte order)\n"
+	"	sltu	$1, %0, %5	\n"
+	"	addu	%0, $1		\n"
+
+	"	addu	%0, %6		# csum\n"
+	"	sltu	$1, %0, %6	\n"
+	"	andi	$12, %2, 3	# calc offset for saddr\n"
+	"	sub	%2, %2, $12	# align pointer\n"
+	"	sll	$12, $12, 0x08	# calc shift left amount\n"
+	"	ori	$13, $0, 0x20	# calc shift right amount\n"
+	"	subu	$13, $13, $12	\n"
+	"	lw	%1, 0(%2)	# four words source address\n"
+	"	lw	$14, 4(%2)	# and next word\n"
+	"	sllv	%1, %1, $12	# shift word1 left\n"
+	"	srlv	$14, $14, $13	# shift word2 right\n"
+	"	or	%1, %1, $14	# or together\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 4(%2)	\n"
+	"	lw	$14, 8(%2)	\n"
+	"	sllv	%1, %1, $12	\n"
+	"	srlv	$14, $14, $13	\n"
+	"	or	%1, %1, $14	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 8(%2)	\n"
+	"	lw	$14, 12(%2)	\n"
+	"	sllv	%1, %1, $12	\n"
+	"	srlv	$14, $14, $13	\n"
+	"	or	%1, %1, $14	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 12(%2)	\n"
+	"	lw	$14, 16(%2)	\n"
+	"	sllv	%1, %1, $12	\n"
+	"	srlv	$14, $14, $13	\n"
+	"	or	%1, %1, $14	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	srl	$12, $12, 0x08	# Undo damage to saddr\n"
+	"	addu	%2, %2, $12	\n"
+
+	"	andi	$12, %3, 3	# calc offset for daddr\n"
+	"	sub	%3, %3, $12	# align pointer\n"
+	"	sll	$12, $12, 0x08	# calc shift left amount\n"
+	"	ori	$13, $0, 0x20	# calc shift right amount\n"
+	"	subu	$13, $13, $12	\n"
+	"	lw	%1, 0(%3)	# four words source address\n"
+	"	lw	$14, 4(%3)	# and next word\n"
+	"	sllv	%1, %1, $12	# shift word1 left\n"
+	"	srlv	$14, $14, $13	# shift word2 right\n"
+	"	or	%1, %1, $14	# or together\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 4(%3)	\n"
+	"	lw	$14, 8(%3)	\n"
+	"	sllv	%1, %1, $12	\n"
+	"	srlv	$14, $14, $13	\n"
+	"	or	%1, %1, $14	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 8(%3)	\n"
+	"	lw	$14, 12(%3)	\n"
+	"	sllv	%1, %1, $12	\n"
+	"	srlv	$14, $14, $13	\n"
+	"	or	%1, %1, $14	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	lw	%1, 12(%3)	\n"
+	"	lw	$14, 16(%3)	\n"
+	"	sllv	%1, %1, $12	\n"
+	"	srlv	$14, $14, $13	\n"
+	"	or	%1, %1, $14	\n"
+	"	addu	%0, $1		\n"
+	"	addu	%0, %1		\n"
+	"	sltu	$1, %0, %1	\n"
+
+	"	srl	$12, $12, 0x08	# Undo damage to daddr\n"
+	"	addu	%3, %3, $12	\n"
+
+	"	addu	%0, $1		# Add final carry\n"
+	"	.set	pop"
+	: "=r" (sum), "=r" (proto)
+	: "r" (saddr), "r" (daddr),
+	"" (htonl(len)), "1" (htonl(proto)), "r" (sum)
+	: "$12", "$13", "$14");
+
+	return csum_fold(sum);
+}
+
 #endif /* _ASM_CHECKSUM_H */
